{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\rkdwn\\anaconda3\\lib\\site-packages (4.5.1.48)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\rkdwn\\anaconda3\\lib\\site-packages (from opencv-python) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.overlay함수를 통해 pos위치로부터 glasses 안경이미지를 영상에 합성해 줄 것입니다.\n",
    "2.실제 합성을 수행할 부분 영상의 좌표를 계산해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay(img, glasses, pos):#pos위치부터 글래스이미지를 안경영상에 합성\n",
    "    # 실제 합성을 수행할 부분 영상 좌표 계산\n",
    "    sx = pos[0]#start x\n",
    "    ex = pos[0] + glasses.shape[1] #glasses의 width와 height를 더한다.\n",
    "    sy = pos[1]#start y\n",
    "    ey = pos[1] + glasses.shape[0]  # glasses의 width와 height를 더한다.\n",
    "\n",
    "    # 혹시나 합성할 영역이 입력 영상 크기를 벗어나면 무시\n",
    "    if sx < 0 or sy < 0 or ex > img.shape[1] or ey > img.shape[0]:\n",
    "        return\n",
    "\n",
    "    # 부분 영상 참조. img1: 입력 영상의 부분 영상, img2: 안경 영상의 부분 영상\n",
    "    img1 = img[sy:ey, sx:ex]   # shape=(h, w, 3)\n",
    "    img2 = glasses[:, :, 0:3]  # shape=(h, w, 3) #0:3은 0,1,2번이다. BGR\n",
    "    alpha = 1. - (glasses[:, :, 3] / 255.)  # shape=(h, w) \n",
    "    #3은 3번이다 알파채널. 가중치역할을 한다.\n",
    "    #알파는 실수형 형태의 행렬이다.\n",
    "\n",
    "    # BGR 채널별로 두 부분 영상의 가중합\n",
    "    img1[..., 0] = (img1[..., 0] * alpha + img2[..., 0] * (1. - alpha)).astype(np.uint8)\n",
    "    img1[..., 1] = (img1[..., 1] * alpha + img2[..., 1] * (1. - alpha)).astype(np.uint8)\n",
    "    img1[..., 2] = (img1[..., 2] * alpha + img2[..., 2] * (1. - alpha)).astype(np.uint8)\n",
    "    #BGR로 따로따로 연산을 하도록 한다.\n",
    "    #타입만 적당히 지정해주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "#카메라 오픈해서 Cap변수에 저장\n",
    "if not cap.isOpened():\n",
    "    print('Camera open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "#기본적인 카메라의 프레임 크기 640x480이 보통 기본\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "#DIVX로 코덱을 사용\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 30, (w, h))\n",
    "#output.avi 파일러 이름저장\n",
    "\n",
    "# Haar-like XML 파일 열기\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "#얼굴검출\n",
    "eye_classifier = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "#눈검출 XML 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if face_classifier.empty() or eye_classifier.empty():\n",
    "    print('XML load failed!')\n",
    "    sys.exit()\n",
    "#예외처리\n",
    "\n",
    "# 안경 PNG 파일 열기 (Image from http://www.pngall.com/)\n",
    "glasses = cv2.imread('glasses.png', cv2.IMREAD_UNCHANGED)\n",
    "#채널이 네개로 되어있는 파일, \n",
    "#합성할 png파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if glasses is None:\n",
    "    print('PNG image open failed!')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ew, eh = glasses.shape[:2]  # 가로, 세로 크기\n",
    "ex1, ey1 = 240, 300  # 왼쪽 눈 좌표\n",
    "ex2, ey2 = 660, 300  # 오른쪽 눈 좌표\n",
    "#합성할 안경영상의 눈위치 좌표. \n",
    "#왼쪽눈 좌표, 오른쪽눈의 좌표이며, \n",
    "#실제 검출안 눈과 거리와 상대적으로 거리를 맞춰줄 것이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매 프레임에 대해 얼굴 검출 및 안경 합성\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    #매 프레임마다 얼굴 검출\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 얼굴 검출하는 함수, 속도조절하려고 값들 좀 수정, 디폴트로안하고\n",
    "    faces = face_classifier.detectMultiScale(frame, scaleFactor=1.2,\n",
    "                                             minSize=(100, 100), maxSize=(400, 400))\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        #cv2.rectangle(frame, (x, y, w, h), (255, 0, 255), 2)\n",
    "\n",
    "        # 눈 검출\n",
    "        faceROI = frame[y:y + h // 2, x:x + w]\n",
    "        eyes = eye_classifier.detectMultiScale(faceROI)\n",
    "\n",
    "        # 눈을 2개 검출한 것이 아니라면 무시\n",
    "        if len(eyes) != 2:\n",
    "            continue\n",
    "\n",
    "        # 두 개의 눈 중앙 위치를 (x1, y1), (x2, y2) 좌표로 저장\n",
    "        x1 = x + eyes[0][0] + (eyes[0][2] // 2) #왼쪽눈의 가로크기\n",
    "        y1 = y + eyes[0][1] + (eyes[0][3] // 2) #왼쪽눈의 세로크기\n",
    "        x2 = x + eyes[1][0] + (eyes[1][2] // 2) #오른쪽눈의 가로크기\n",
    "        y2 = y + eyes[1][1] + (eyes[1][3] // 2) #오른쪽눈의 세로크기\n",
    "        #x하고 y는 얼굴 검출위치의 좌측상단인데 x,y는 얼굴 부분영상의 좌표이다.\n",
    "        #얼굴검출한 위치에 눈검출한 위치를 더해야한다. 그래야 전체영상에서의 왼쪽눈 오른쪽눈을 계산할 수 있다.\n",
    "\n",
    "        if x1 > x2:\n",
    "            x1, y1, x2, y2 = x2, y2, x1, y1\n",
    "        #왼쪽눈과 오른쪽눈 순서가 바뀔수있기때문에 오른쪽눈이 왼쪽눈보다 작으면 바꿔준다.\n",
    "\n",
    "        #cv2.circle(faceROI, (x1, y1), 5, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        #cv2.circle(faceROI, (x2, y2), 5, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # 두 눈 사이의 거리를 이용하여 스케일링 팩터를 계산 (두 눈이 수평하다고 가정)\n",
    "        fx = (x2 - x1) / (ex2 - ex1)\n",
    "        #실제 입력영상에서의 두눈의 좌표/ 안경영상에서의 두눈의 좌표 비율을 fx에 저장\n",
    "        glasses2 = cv2.resize(glasses, (0, 0), fx=fx, fy=fx, interpolation=cv2.INTER_AREA)\n",
    "        #보통 작아지는 형태로 바뀔것이다.\n",
    "\n",
    "        # 크기 조절된 안경 영상을 합성할 위치 계산 (좌상단 좌표)\n",
    "        #리사이즈한 png 영상이 실제 카메라 프레임 어느 위치부터 시작해서 합성을 할거냐를 pos에 저장\n",
    "        pos = (x1 - int(ex1 * fx), y1 - int(ey1 * fx))\n",
    "\n",
    "        # 영상 합성\n",
    "        overlay(frame, glasses2, pos)\n",
    "        #리사이즈된 안경영상을 합성. pos위치부터 합성\n",
    "\n",
    "    # 프레임 저장 및 화면 출력\n",
    "    out.write(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
